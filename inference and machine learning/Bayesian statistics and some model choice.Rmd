---
title: "Bayesian statistics and some model choice"
author: "gean piere ventura cruz"
date: '2022-10-17'
output: html_document
---

```{r setup, include=FALSE}
library(RCurl)
set.seed(960618) 
link <- "https://raw.githubusercontent.com/mskoldSU/MT5003_HT17/master/Projekt/proj_data.csv"
data_individ <-read.csv(file = link)
data_individ
idx <- sample(1:nrow(data_individ), 1000)
data_individ <- data_individ[idx, ]
save(data_individ, file = "proj_data.Rdata")
```

```{r, echo=FALSE}
L <- function(theta, y, X, N){
  pi <- matrix(0, nrow = 1, ncol = N)
  for (i in 1:N) {
    pi[i]<- 1/(1+exp(-X[i,]%*%theta))
  }
  likelihood <- prod(dbinom(y,1,pi)) 
  return(likelihood)
}

#L(theta0,y,X,1000) 

l <- function(theta, y, X, N){
  log_likelihood <- L(theta, y,X,N)
  return(log(log_likelihood))
}

#l(theta0,y,X,1000)

S <- function(theta, y, X, N){
  p <- matrix(0, nrow = 1, ncol = N) 
  for (i in 1:N){
    p[i] <- 1/(1+exp(-X[i,]%*%theta)) #creating the p vector
  }
  transposed_p <- t(p) #transpose p vector 
  score <- t(X)%*%(y-transposed_p)
  return(score)
}

#S(theta0,y,X,1000)

I <- function(theta, y, X, N){
  v <- matrix(0, nrow = 1, ncol = N)
  for (i in 1:N) {
    v[i] <- (1/(1+exp(-X[i,]%*%theta)))%*%(1-(1/(1+exp(-X[i,]%*%theta)))) #creating the v vector and storing it in a diagonal matrix
  }
  D <- diag(as.vector(v))
  return(t(X)%*%D%*%X)
}

#I(theta0,y,X,1000)

NR <- function(theta0, niter, y, X){
  old_theta <- theta0
  for (i in 1:niter){
    theta_ml <- old_theta+solve(I(old_theta,y ,X, length(y)))%*%S(old_theta, y, X, length(y))
    old_theta <- theta_ml
  }
  return(theta_ml) 
}

modell <- glm(Resultat ~ Alder + Kon + Utbildare,
              data = data_individ,
              family = "binomial")

#summary(modell)

y <- matrix(data_individ$Resultat, ncol = 1)
X <- model.matrix(Resultat ~ Alder + Kon + Utbildare, data = data_individ)


#head(data_individ[,-1])
theta0 <- c(0,0,0,0)
theta_est <- c(NR(theta0, niter = 3, y, X))

#theta_est #estima

ml_theta <- NR(theta0, niter = 3, y, X)
#ml_theta
```

Task 1

We are still using the functions from the "Likelihood, numerical optimization and the Bootstrap" project. We are going to compute AIC for the model using functions from the "Score-, Wald- and likelihood ratio tests" project and make sure it agrees with R’s value. Also compute the corresponding value based on leave-one-out cross validation 

```{r}
summary(modell)

AIC <- -2*l(ml_theta,y,X,1000)+2*4
AIC

```

The computed AIC, 1279.53, looks similar to the AIC, 1279.5, from the regression model.

```{r}

cross_validate<- 0

for (i in 1:1000){
  new_MLE <- NR(theta0, niter = 3, y[-i], X[-i,])
  loglikelihood <- log(dbinom(y[i], 1, (1+exp(-X[i,] %*% new_MLE))**(-1)))
  cross_validate <- cross_validate + loglikelihood
}

cross_validate_avg <- cross_validate / 1000 
cross_validate_avg
approx_cross_avg <- -AIC/2000
approx_cross_avg
```

We can observe that the cross validated average is quite similar to the mean of our AIC value.

Task 2

In this part we are going to write a code for the posterior density.

```{r}

post <- function(theta, y, X){
  prior <- exp((-1/2)*t(theta) %*% diag((1/100), nrow = 4, ncol =4) %*% theta)
  posteori <- prior * L(theta, y, X, length(y))
}

#Xtest <- cbind(1, 18:25, rep(c(0, 1), 4), rep(c(1, 1, 0, 0), 2))
#ytest <- c(rep(TRUE, 4), rep(FALSE, 4))
#post(c(260, -10, 10, -20), ytest, Xtest) / post(c(270, -15, 15, -25), ytest , Xtest)
```

Task 3

In the last part we are going to implement a metropolis - hasting algorithm that given a starting value, simulates from the posterior distribution of θ. We are going to use the algorithm to sample (at least) 10000 vectors θ from the posterior. A suitable choice of sigma (the step-size) is the vector of ML-estimator standard errors. After that we are going to plot the draws for each parameter, plot histograms of the parameters posteriors, then use the samples to approximate posterior means and 95% credibility intervals (using ´quantile´) for the parameters. Compare with the results of the frequentist analysis and lastly find the probability of a pass for someone given my age and sex.  

```{r}

#post <- function(theta){L.weib(theta[1], theta[2], data = ac)}
N <- 10000 #Antal iterationer
theta <- matrix(nrow = N, ncol = 4) #number of col = 4
theta[1,] <- theta_est #Startvärde
sigma <- c(summary(modell)$coefficient[,2]) #Steglängd
for (i in 2:N){
  theta.star <- theta[i-1,] + rnorm(2) * sigma
  if (post(c(theta.star),y,X) / post(c(theta[i-1,]),y,X) > runif(1)){ #using our post function
   theta[i,] <- theta.star 
  }
  else{
    theta[i,] <- theta[i-1,]
  }
    
}
```

```{r}
par(mfrow=c(2,2))
plot(theta[,1], type = "l", ylab = "intercept")
plot(theta[,2], type = "l", ylab = "alder")
plot(theta[,3], type = "l",ylab = "konman")
plot(theta[,4], type = "l",ylab = "utbildare")
```


```{r}
par(mfrow=c(2,2))
hist(theta[,1],xlab = "intercept", main = "histogram of intercept")
hist(theta[,2], xlab = "alder", main = "histogram of alder")
hist(theta[,3], xlab = "konman", main = "histogram of konman")
hist(theta[,4], xlab = "utbildare", main = "histogram of utbildare")
```

```{r}
posterior_mean <- c(mean(theta[,1]), mean(theta[,2]), mean(theta[,3]), mean(theta[,4]))
posterior_mean
theta_est
```

The results obtained from the posterior mean are indeed quite similar to those from the frequentist analysis.

```{r}
x <- c(1, 26, 0, 0)
p <- 1 / (1+exp(-x %*% posterior_mean))
p
```

The approximate of P(Y∗=1|y) given my sex and age is equal to 30%










